{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7404c40f",
   "metadata": {},
   "source": [
    "### 使用routechain来实现判断存款还是取款"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73af9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "withdraw_template = \"\"\"你是银行资深柜员，非常善于处理客户取款问题。\n",
    "你会判断客户到银行做的是什么交易，识别出取款交易给设置当前的 pcode=200101。\n",
    "你会从问题中识别出客户要取多少钱，比如取3000， 那amount=3000。\n",
    "你会从客户是否是代为他人办理，如果是代办，需要设置agent=true，如果是本人办理或没有识别出来，则设置agent=false\n",
    "\n",
    "这是一个客户业务：\n",
    "{input}\n",
    "\n",
    "请只输出pcode，amount，agent的信息\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "despoit_template =  \"\"\"你是银行资深柜员，非常善于处理客户存款问题。\n",
    "你会判断客户到银行做的是什么交易，识别出存款交易给设置当前的 pcode=200102。\n",
    "你会从问题中识别出客户要存多少钱，比如存3000， 那amount=3000。\n",
    "\n",
    "这是一个客户业务：\n",
    "{input}\n",
    "\n",
    "请只输出pcode和amount的信息\n",
    "\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"存款\",\n",
    "        \"description\": \"适用于回答存款问题\",\n",
    "        \"prompt_template\": despoit_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"取款\",\n",
    "        \"description\": \"适用于回答取款问题\",\n",
    "        \"prompt_template\": withdraw_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "58eee17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model=\"llama3.1:latest\",temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3749db47",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "# 遍历prompt_infos列表，为每个信息创建一个LLMChain。\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]  # 提取名称\n",
    "    prompt_template = p_info[\"prompt_template\"]  # 提取模板\n",
    "    # 创建PromptTemplate对象\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    # 使用上述模板和llm对象创建LLMChain对象\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    # 将新创建的chain对象添加到destination_chains字典中\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 创建一个默认的ConversationChain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "63d61c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain.chains.conversation.base.ConversationChain"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(default_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ff0f988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bedc6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从prompt_infos中提取目标信息并将其转化为字符串列表\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "# 使用join方法将列表转化为字符串，每个元素之间用换行符分隔\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "# 根据MULTI_PROMPT_ROUTER_TEMPLATE格式化字符串和destinations_str创建路由模板\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "# 创建路由的PromptTemplate\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1f68e8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['存款: 适用于回答存款问题', '取款: 适用于回答取款问题']\n",
      "存款: 适用于回答存款问题\n",
      "取款: 适用于回答取款问题\n"
     ]
    }
   ],
   "source": [
    "print(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e56f64c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7dc9a16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "存款: 适用于回答存款问题\n",
      "取款: 适用于回答取款问题\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c412cf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建MultiPromptChain对象，其中包含了路由链，目标链和默认链。\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "720bfce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "取款: {'input': '张三到柜面取了5000块钱'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '张三到柜面取了5000块钱', 'text': '基于你的需求，我可以为这个客户业务设置 pcode 和 amount 的值：\\n\\n*   pcode：200101（取款交易）\\n*   amount：5000（客户取出了 5000 块钱）'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"张三到柜面取钱，他需要取5000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "47c0b992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "存款: {'input': '李四到柜面，存入 4000 元'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '李四到柜面，存入 4000 元', 'text': '好的！根据李四的行为，我可以确定他是在进行存款交易。因此：\\n\\npcode = 200102\\namount = 4000'}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    chain.invoke(\n",
    "        \"李四到柜面，要存4000元。\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3dbbdb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_chain.verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c0a06e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "取款: {'input': '王五到柜面取出6千'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': '王五到柜面取出6千', 'text': 'pcode = 200101\\namount = 6000'}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"王五到柜面取款6000\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec56b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
