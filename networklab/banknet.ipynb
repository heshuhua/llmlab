{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "464230bc",
   "metadata": {},
   "source": [
    "完成对话运行地<a href=\"https://colab.research.google.com/github/heshuhua/llmlab/blob/main/networklab/banknet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2754edcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_community.chat_models.zhipuai import ChatZhipuAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "withdraw_template = \"\"\"你是银行资深柜员，非常善于处理客户取款问题。\n",
    "你会判断客户到银行做的是什么交易，识别出取款交易给设置当前的 pcode=200101。\n",
    "你会从问题中识别出客户要取多少钱，比如取3000， 那amount=3000。\n",
    "你会从客户是否是代为他人办理，如果是代办，需要设置agent=true，如果是本人办理或没有识别出来，则设置agent=false\n",
    "\n",
    "这是一个客户业务：\n",
    "{input}\n",
    "\n",
    "请只输出pcode，amount，agent的信息\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "despoit_template =  \"\"\"你是银行资深柜员，非常善于处理客户存款问题。\n",
    "你会判断客户到银行做的是什么交易，识别出存款交易给设置当前的 pcode=200102。\n",
    "你会从问题中识别出客户要存多少钱，比如存3000， 那amount=3000。\n",
    "\n",
    "这是一个客户业务：\n",
    "{input}\n",
    "\n",
    "请只输出pcode和amount的信息\n",
    "\"\"\"\n",
    "\n",
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"存款\",\n",
    "        \"description\": \"适用于回答存款问题\",\n",
    "        \"prompt_template\": despoit_template,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"取款\",\n",
    "        \"description\": \"适用于回答取款问题\",\n",
    "        \"prompt_template\": withdraw_template,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b35eb713",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatZhipuAI(model='glm-z1-air',api_key=\"d8ff456cda9f41a18f1d27b1841478ba.yxvqZIe8nRYC5UFB\",base_url=\"https://open.bigmodel.cn/api/paas/v4\",temperature=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "68855dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "# 遍历prompt_infos列表，为每个信息创建一个LLMChain。\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]  # 提取名称\n",
    "    prompt_template = p_info[\"prompt_template\"]  # 提取模板\n",
    "    # 创建PromptTemplate对象\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"input\"])\n",
    "    # 使用上述模板和llm对象创建LLMChain对象\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    \n",
    "    # 将新创建的chain对象添加到destination_chains字典中\n",
    "    destination_chains[name] = chain\n",
    "\n",
    "# 创建一个默认的ConversationChain\n",
    "default_chain = ConversationChain(llm=llm, output_key=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82c180d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23ebe458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从prompt_infos中提取目标信息并将其转化为字符串列表\n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "# 使用join方法将列表转化为字符串，每个元素之间用换行符分隔\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "# 根据MULTI_PROMPT_ROUTER_TEMPLATE格式化字符串和destinations_str创建路由模板\n",
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations_str)\n",
    "# 创建路由的PromptTemplate\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "# 使用上述路由模板和llm对象创建LLMRouterChain对象\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b03bae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['存款: 适用于回答存款问题', '取款: 适用于回答取款问题']\n",
      "存款: 适用于回答存款问题\n",
      "取款: 适用于回答取款问题\n",
      "Given a raw text input to a language model select the model prompt best suited for the input. You will be given the names of the available prompts and a description of what the prompt is best suited for. You may also revise the original input if you think that revising it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{{{\n",
      "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
      "}}}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is not well suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "{destinations}\n",
      "\n",
      "<< INPUT >>\n",
      "{{input}}\n",
      "\n",
      "<< OUTPUT (must include ```json at the start of the response) >>\n",
      "<< OUTPUT (must end with ```) >>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(destinations)\n",
    "print(destinations_str)\n",
    "print(MULTI_PROMPT_ROUTER_TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "667fa0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建MultiPromptChain对象，其中包含了路由链，目标链和默认链。\n",
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain,\n",
    "    destination_chains=destination_chains,\n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "947fa9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMRouterChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "取款: {'input': '张三到柜面办理取款业务，需要取出5000元人民币。'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '张三到柜面办理取款业务，需要取出5000元人民币。',\n",
       " 'text': '\\n<think>\\n好的，我现在需要处理这个客户张三的取款业务。首先，我要确定他的交易类型。问题中明确提到“取款业务”，所以pcode应该设为200101，这是取款的代码。\\n\\n接下来是金额部分。客户要取出5000元人民币，所以amount直接设为5000。这里没有提到其他费用或不同的货币，所以直接提取数字即可。\\n\\n然后是关于代办的情况。问题里说张三“到柜面办理”，没有提到他是代别人办理，也没有任何暗示代办的信息，比如“代领”、“代取”之类的词汇。因此，agent应该设为false，表示是本人办理。\\n\\n检查一下有没有可能遗漏的地方。比如，是否有可能张三虽然自己来，但实际是代办？但根据问题描述，没有提供这样的信息，所以只能按字面意思处理。因此，确定agent为false是正确的。\\n\\n最后，综合这三个部分，pcode是200101，amount是5000，agent是false。确保输出格式正确，没有多余的内容。\\n</think>\\npcode=200101, amount=5000, agent=false'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "router_chain.verbose = True\n",
    "\n",
    "chain.invoke(\"张三到柜面取钱，他需要取5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa0690f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dgai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
